{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaYxDGyQN3Ji8GNoZh030X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesusGS01/TGINE/blob/main/P2_TGINE_JesusGarciaSalmeron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica 2 : Análisis de información textual en YouTube\n",
        "\n",
        "Alumno: Jesús García Salmerón\n",
        "\n",
        "Convocatoria: Enero, 2024"
      ],
      "metadata": {
        "id": "bvrHSfdS5YkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1 - Extracción de datos de YouTube"
      ],
      "metadata": {
        "id": "UjYuA04C5psm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nonAEk5v8zqV",
        "outputId": "11cc85c3-7b5b-47f1-ce59-cc484efa76e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.110.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JNdFYZ305XvB"
      },
      "outputs": [],
      "source": [
        "# api_key = \"AIzaSyDy1-AChQ-ywxeJoZeHRdF0zl0I5xZIL88\" # Primera\n",
        "# api_key = \"AIzaSyBf0oNdiVZSoFKm1MmS6mL7k0hY_ZPd6sM\" # Segunda\n",
        "# api_key = \"AIzaSyDnifOG2856kcPlM96kwdvWHzANNRIfHks\" # Tercera\n",
        "api_key = \"AIzaSyBXsFiRKyTdFBSwwac1-U8vPk1bF0WU6F0\" # Cuarta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sacamos los IDs de los canales"
      ],
      "metadata": {
        "id": "-GyW3vH38ryp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import json\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "def get_channel_ids(youtube, channel_names, max_results=1):\n",
        "    channel_ids = {}\n",
        "    for channel_name in channel_names:\n",
        "        request = youtube.search().list(\n",
        "            part=\"snippet\",\n",
        "            type=\"channel\",\n",
        "            q=channel_name,\n",
        "            maxResults=max_results\n",
        "        )\n",
        "\n",
        "        response = request.execute()\n",
        "\n",
        "        if 'items' in response and len(response['items']) > 0:\n",
        "            channel_id = response['items'][0]['snippet']['channelId']\n",
        "            channel_ids[channel_name] = channel_id\n",
        "\n",
        "    return channel_ids\n",
        "\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "# Configurar el servicio de YouTube\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "\n",
        "# Crear el cliente de YouTube con la API Key\n",
        "youtube = build(api_service_name, api_version, developerKey=api_key)\n",
        "\n",
        "canales_viaje = [\"Lethal Crysis\",\"Mochileros\",\"Sekaivlog\",\"Molaviajar\",\"Paco Nadal\",\"Oscar Alejandro\",\"Enrique Álex\",\"Luisito Comunica\",\"alanxelmundo\",\"Kike Arnaiz\"]\n",
        "canales_deporte = [\"demas6Basket\",\"ACB\",\"Baloncesto España\", \"Hatch - NBA\", \"Mundo Maldini\",\"TyC Sports\",\"ESPN Deportes\",\"La Media Inglesa\",\"Cracks\",\"LALIGA EA Sports\"]\n",
        "canales_comida = [\"¡Que el papeo te acompañe!\",\"Cocinando con Dario\",\"Lolita la pastelera\",\"PostresSaludables\",\"La Cocina Del Pirata\", \"Diegodoal\", \"GeritaVal\",\"El Mundo En Recetas\",\"Casserola club\", \"Recetas y Más TV\"]\n",
        "\n",
        "# Temática de los canales que quieres buscar\n",
        "temas = [\"Viaje\",\"Deportes\",\"Comida\"]  # Reemplaza con la temática que buscas\n",
        "\n",
        "# Diccionario para almacenar los IDs de los canales por temática\n",
        "canales_por_tematica = {\n",
        "    \"Viaje\": get_channel_ids(youtube, canales_viaje),\n",
        "    \"Deportes\": get_channel_ids(youtube, canales_deporte),\n",
        "    \"Cocina\": get_channel_ids(youtube, canales_comida)\n",
        "}\n",
        "\n",
        "# Guardar los datos en un archivo JSON\n",
        "save_to_json(canales_por_tematica, 'canales_por_tematica.json')\n",
        "print(\"Datos guardados en canales_por_tematica.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N56JFKe78m8O",
        "outputId": "5dab7110-207d-49ce-bf0d-117c391b8e18"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos guardados en canales_por_tematica.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sacamos la informacion de cada canal"
      ],
      "metadata": {
        "id": "1rhPTLfF8wA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def get_videos(youtube, channel_id, max_results=100):\n",
        "    request = youtube.search().list(\n",
        "        part=\"snippet\",\n",
        "        type=\"video\",\n",
        "        channelId=channel_id,\n",
        "        maxResults=max_results\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    video_ids = [item['id']['videoId'] for item in response['items']]\n",
        "    return video_ids\n",
        "\n",
        "\n",
        "def get_video_details(youtube, video_id):\n",
        "    request = youtube.videos().list(\n",
        "        part=\"snippet\",\n",
        "        id=video_id\n",
        "    )\n",
        "\n",
        "    response = request.execute()\n",
        "\n",
        "    if 'items' in response and len(response['items']) > 0:\n",
        "        video_info = response['items'][0]['snippet']\n",
        "        return {\n",
        "            \"channel\": video_info['channelTitle'],\n",
        "            \"date\": video_info['publishedAt'],\n",
        "            \"title\": video_info['title'],\n",
        "            \"description\": video_info['description']\n",
        "        }\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_comments(youtube, video_id, max_results=50):\n",
        "    request_comments = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        maxResults=max_results\n",
        "    )\n",
        "    response_comments = request_comments.execute()\n",
        "\n",
        "    comments = []\n",
        "\n",
        "    for item in response_comments.get('items', []):\n",
        "        comment_data = {\n",
        "            \"user\": item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
        "            \"comment\": item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
        "            \"sentiment\": \"\"  # Puedes añadir análisis de sentimiento aquí si deseas\n",
        "        }\n",
        "        comments.append(comment_data)\n",
        "\n",
        "    if not comments:\n",
        "        print(f\"No se pudieron encontrar comentarios para el video: {video_id}\")\n",
        "\n",
        "    return comments\n",
        "\n",
        "def read_json(file_name):\n",
        "    with open(file_name, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def save_channel_data(directory, channel_name, tema, data):\n",
        "    # Reemplazar caracteres no válidos en el nombre del canal\n",
        "    invalid_chars = ['/', '\\\\', '?', '%', '*', ':', '|', '\"', '<', '>', '.']\n",
        "    for char in invalid_chars:\n",
        "        channel_name = channel_name.replace(char, '_')\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    file_name = f\"{directory}/{channel_name}.json\"  # Nombre del archivo con el nombre del canal\n",
        "    with open(file_name, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "canales_por_tematica = read_json('canales_por_tematica.json')\n",
        "\n",
        "# Verificar si el directorio existe y eliminarlo si es así\n",
        "if os.path.exists(\"channelsData\"):\n",
        "    shutil.rmtree(\"channelsData\")\n",
        "\n",
        "# Crear el directorio\n",
        "os.makedirs(\"channelsData\")\n",
        "\n",
        "for tema, canales in canales_por_tematica.items():\n",
        "    for canal, canal_id in canales.items():\n",
        "        videos = get_videos(youtube, canal_id)\n",
        "        videos_data = []\n",
        "\n",
        "        print(\"CANAL ACTUAL ->\"+canal)\n",
        "        for video_id in videos:\n",
        "            video_info = get_video_details(youtube, video_id)\n",
        "            if video_info:\n",
        "                comments = get_comments(youtube, video_id)\n",
        "                video_data = {\n",
        "                    \"date\": video_info[\"date\"],\n",
        "                    \"title\": video_info[\"title\"],\n",
        "                    \"description\": video_info[\"description\"],\n",
        "                    \"comments\": comments\n",
        "                }\n",
        "                videos_data.append(video_data)\n",
        "\n",
        "        # Crear la estructura de datos para el archivo JSON por tema y canal\n",
        "        canal_data = {\n",
        "            \"channel\": canal,\n",
        "            \"type\": tema,\n",
        "            \"videos\": videos_data\n",
        "        }\n",
        "\n",
        "        save_channel_data(f\"channelsData/{tema}\", canal, tema, canal_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv0onwKR-gMq",
        "outputId": "f97b53b7-9a1b-4ee7-a0da-c1c083c74f4e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CANAL ACTUAL ->demas6Basket\n",
            "CANAL ACTUAL ->ACB\n",
            "No se pudieron encontrar comentarios para el video: 2D2vBZCpfAI\n",
            "No se pudieron encontrar comentarios para el video: HI8nYtLaZlI\n",
            "No se pudieron encontrar comentarios para el video: 1wuuBZ1_zoo\n",
            "No se pudieron encontrar comentarios para el video: cqZ8sRCj0Yc\n",
            "No se pudieron encontrar comentarios para el video: dmXs-8NlSSE\n",
            "No se pudieron encontrar comentarios para el video: pjsmFAQc7eI\n",
            "No se pudieron encontrar comentarios para el video: uBakR1LaseE\n",
            "No se pudieron encontrar comentarios para el video: yOV7YxSrVdo\n",
            "CANAL ACTUAL ->Baloncesto España\n",
            "No se pudieron encontrar comentarios para el video: tEz0SElJ7ho\n",
            "No se pudieron encontrar comentarios para el video: AgoFLXJi4i0\n",
            "No se pudieron encontrar comentarios para el video: v_9ofqJU3fE\n",
            "No se pudieron encontrar comentarios para el video: ikez4wrgais\n",
            "No se pudieron encontrar comentarios para el video: MnKLs0IFIrA\n",
            "No se pudieron encontrar comentarios para el video: 1OcyAutpA3s\n",
            "No se pudieron encontrar comentarios para el video: XlnWfuWpjoI\n",
            "No se pudieron encontrar comentarios para el video: zZ59XwdjrQs\n",
            "No se pudieron encontrar comentarios para el video: l3lFfHzu2DA\n",
            "No se pudieron encontrar comentarios para el video: pqJlX5RFbsU\n",
            "CANAL ACTUAL ->Hatch - NBA\n",
            "CANAL ACTUAL ->Mundo Maldini\n",
            "CANAL ACTUAL ->TyC Sports\n",
            "CANAL ACTUAL ->ESPN Deportes\n",
            "CANAL ACTUAL ->La Media Inglesa\n",
            "CANAL ACTUAL ->Cracks\n",
            "CANAL ACTUAL ->LALIGA EA Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2 - Clasificador del tipo de canal"
      ],
      "metadata": {
        "id": "fGX8LS7dVlEa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFIvP2fFVksZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}