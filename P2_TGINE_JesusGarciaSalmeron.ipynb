{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhx2RxqRmzhN1cxlkOMDv8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesusGS01/TGINE/blob/main/P2_TGINE_JesusGarciaSalmeron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica 2 : Análisis de información textual en YouTube\n",
        "\n",
        "Alumno: Jesús García Salmerón\n",
        "\n",
        "Convocatoria: Enero, 2024"
      ],
      "metadata": {
        "id": "bvrHSfdS5YkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1 - Extracción de datos de YouTube"
      ],
      "metadata": {
        "id": "UjYuA04C5psm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nonAEk5v8zqV",
        "outputId": "63352d72-b814-4b22-9668-b07322194e73"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.110.0-py2.py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "Successfully installed google-api-python-client-2.110.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JNdFYZ305XvB"
      },
      "outputs": [],
      "source": [
        "# api_key = \"AIzaSyDlKeguAaGndMt3MrZzO9PPyQShDxe5NzI\" # Primera\n",
        "# api_key = \"AIzaSyDzZqlb5Pf9GXXhMFZxjCxt7AyToXqOIp8\" # Segunda\n",
        "api_key = \"AIzaSyDQj7I9mDUPDIe9Mbw7wy-dZjXjFr-ekDk\" # Tercera"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sacamos los IDs de los canales"
      ],
      "metadata": {
        "id": "-GyW3vH38ryp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import json\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "def get_channel_ids(youtube, channel_names, max_results=1):\n",
        "    channel_ids = {}\n",
        "    for channel_name in channel_names:\n",
        "        request = youtube.search().list(\n",
        "            part=\"snippet\",\n",
        "            type=\"channel\",\n",
        "            q=channel_name,\n",
        "            maxResults=max_results\n",
        "        )\n",
        "\n",
        "        response = request.execute()\n",
        "\n",
        "        if 'items' in response and len(response['items']) > 0:\n",
        "            channel_id = response['items'][0]['snippet']['channelId']\n",
        "            channel_ids[channel_name] = channel_id\n",
        "\n",
        "    return channel_ids\n",
        "\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "# Configurar el servicio de YouTube\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "\n",
        "# Crear el cliente de YouTube con la API Key\n",
        "youtube = build(api_service_name, api_version, developerKey=api_key)\n",
        "\n",
        "canales_viaje = [\"Lethal Crysis\",\"Alex Tienda\",\"Mochileros\",\"Molaviajar\",\"Paco Nadal\",\"Oscar Alejandro\",\"Enrique Álex\",\"Luisito Comunica\",\"alanxelmundo\",\"Kike Arnaiz\"]\n",
        "canales_deporte = [\"demas6Basket\",\"ACB\",\"Leandro Carranza - Análisis NBA\", \"Hatch - NBA\", \"Mundo Maldini\",\"TyC Sports\",\"ESPN Deportes\",\"La Media Inglesa\",\"Cracks\",\"LALIGA EA Sports\"]\n",
        "canales_comida = [\"¡Que el papeo te acompañe!\",\"Cocinando con Dario\",\"Lolita la pastelera\",\"PostresSaludables\",\"La Cocina Del Pirata\", \"Diegodoal\", \"Las Recetas de MJ\",\"El Mundo En Recetas\",\"Casserola club\", \"Recetas y Más TV\"]\n",
        "\n",
        "# Temática de los canales que quieres buscar\n",
        "temas = [\"Viaje\",\"Deportes\",\"Comida\"]  # Reemplaza con la temática que buscas\n",
        "\n",
        "# Diccionario para almacenar los IDs de los canales por temática\n",
        "canales_por_tematica = {\n",
        "    #\"Viaje\": get_channel_ids(youtube, canales_viaje),\n",
        "    \"Deportes\": get_channel_ids(youtube, canales_deporte),\n",
        "    #\"Cocina\": get_channel_ids(youtube, canales_comida)\n",
        "}\n",
        "\n",
        "# Guardar los datos en un archivo JSON\n",
        "save_to_json(canales_por_tematica, 'canales_por_tematica.json')\n",
        "print(\"Datos guardados en canales_por_tematica.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N56JFKe78m8O",
        "outputId": "25f47872-9856-449c-a896-923347323185"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos guardados en canales_por_tematica.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sacamos la informacion de cada canal"
      ],
      "metadata": {
        "id": "1rhPTLfF8wA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def get_videos(youtube, channel_id):\n",
        "    next_page_token = None\n",
        "    video_ids = []\n",
        "\n",
        "    for i in range(2):\n",
        "      request = youtube.search().list(\n",
        "          part=\"snippet\",\n",
        "          type=\"video\",\n",
        "          channelId=channel_id,\n",
        "          maxResults= 50,\n",
        "          pageToken = next_page_token\n",
        "      )\n",
        "      response = request.execute()\n",
        "\n",
        "      video_ids.extend([item['id']['videoId'] for item in response['items']])\n",
        "\n",
        "      next_page_token = response.get('nextPageToken')\n",
        "      if not next_page_token:\n",
        "        print(\"WARNING: Only 50 videos availables!!!\")\n",
        "        break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "\n",
        "def get_video_details(youtube, video_id):\n",
        "    request = youtube.videos().list(\n",
        "        part=\"snippet\",\n",
        "        id=video_id\n",
        "    )\n",
        "\n",
        "    response = request.execute()\n",
        "\n",
        "    if 'items' in response and len(response['items']) > 0:\n",
        "        video_info = response['items'][0]['snippet']\n",
        "        return {\n",
        "            \"channel\": video_info['channelTitle'],\n",
        "            \"date\": video_info['publishedAt'],\n",
        "            \"title\": video_info['title'],\n",
        "            \"description\": video_info['description']\n",
        "        }\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_comments(youtube, video_id, max_results=10):\n",
        "    request_comments = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        maxResults=max_results\n",
        "    )\n",
        "    response_comments = request_comments.execute()\n",
        "\n",
        "    comments = []\n",
        "\n",
        "    for item in response_comments.get('items', []):\n",
        "        comment_data = {\n",
        "            \"user\": item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
        "            \"comment\": item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
        "            \"sentiment\": \"\"  # Puedes añadir análisis de sentimiento aquí si deseas\n",
        "        }\n",
        "        comments.append(comment_data)\n",
        "\n",
        "    if not comments:\n",
        "        print(f\"No se pudieron encontrar comentarios para el video: {video_id}\")\n",
        "\n",
        "    return comments\n",
        "\n",
        "def read_json(file_name):\n",
        "    with open(file_name, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def save_channel_data(directory, channel_name, tema, data):\n",
        "    # Reemplazar caracteres no válidos en el nombre del canal\n",
        "    invalid_chars = ['/', '\\\\', '?', '%', '*', ':', '|', '\"', '<', '>', '.']\n",
        "    for char in invalid_chars:\n",
        "        channel_name = channel_name.replace(char, '_')\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    file_name = f\"{directory}/{channel_name}.json\"  # Nombre del archivo con el nombre del canal\n",
        "    with open(file_name, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "canales_por_tematica = read_json('canales_por_tematica.json')\n",
        "\n",
        "# Verificar si el directorio existe y eliminarlo si es así\n",
        "if os.path.exists(\"channelsData\"):\n",
        "    shutil.rmtree(\"channelsData\")\n",
        "\n",
        "# Crear el directorio\n",
        "os.makedirs(\"channelsData\")\n",
        "\n",
        "for tema, canales in canales_por_tematica.items():\n",
        "    for canal, canal_id in canales.items():\n",
        "        videos = get_videos(youtube, canal_id)\n",
        "        videos_data = []\n",
        "\n",
        "        print(\"CANAL ACTUAL ->\"+canal)\n",
        "        for video_id in videos:\n",
        "            video_info = get_video_details(youtube, video_id)\n",
        "            if video_info:\n",
        "                comments = get_comments(youtube, video_id)\n",
        "                video_data = {\n",
        "                    \"date\": video_info[\"date\"],\n",
        "                    \"title\": video_info[\"title\"],\n",
        "                    \"description\": video_info[\"description\"],\n",
        "                    \"comments\": comments\n",
        "                }\n",
        "                videos_data.append(video_data)\n",
        "\n",
        "        # Crear la estructura de datos para el archivo JSON por tema y canal\n",
        "        canal_data = {\n",
        "            \"channel\": canal,\n",
        "            \"type\": tema,\n",
        "            \"videos\": videos_data\n",
        "        }\n",
        "\n",
        "        save_channel_data(f\"channelsData/{tema}\", canal, tema, canal_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "Jv0onwKR-gMq",
        "outputId": "ed9d8ea2-24a8-42bd-cb61-d8664b542fcf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CANAL ACTUAL ->demas6Basket\n",
            "WARNING: Only 50 videos availables!!!\n",
            "CANAL ACTUAL ->ACB\n",
            "CANAL ACTUAL ->Leandro Carranza - Análisis NBA\n",
            "WARNING: Only 50 videos availables!!!\n",
            "CANAL ACTUAL ->Hatch - NBA\n",
            "CANAL ACTUAL ->Mundo Maldini\n",
            "CANAL ACTUAL ->TyC Sports\n",
            "CANAL ACTUAL ->ESPN Deportes\n",
            "CANAL ACTUAL ->La Media Inglesa\n",
            "CANAL ACTUAL ->Cracks\n",
            "CANAL ACTUAL ->LALIGA EA Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"quotaExceeded\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HttpError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-0c43aeb6eb85>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CANAL ACTUAL ->\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcanal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvideo_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mvideo_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_video_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myoutube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvideo_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myoutube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-0c43aeb6eb85>\u001b[0m in \u001b[0;36mget_video_details\u001b[0;34m(youtube, video_id)\u001b[0m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'items'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=snippet&id=TU6zM63GuLo&key=AIzaSyDQj7I9mDUPDIe9Mbw7wy-dZjXjFr-ekDk&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2 - Clasificador del tipo de canal"
      ],
      "metadata": {
        "id": "fGX8LS7dVlEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraemos los datos para train y validation"
      ],
      "metadata": {
        "id": "d-EMXmZ5gxJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Train\n",
        "train_data = []\n",
        "train_labels = []\n",
        "# Validation\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "# Directorio padre\n",
        "directory = 'channelsData'\n",
        "\n",
        "# Contadores para saber el numero de canales\n",
        "count_cocina = 0\n",
        "count_deportes = 0\n",
        "count_viaje = 0\n",
        "missing=0\n",
        "\n",
        "# Recorrer los directorios en channelsData\n",
        "for root, dirs, files in os.walk(directory):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            data_type = data['type']\n",
        "            if data_type == \"Cocina\":\n",
        "              count_cocina += 1\n",
        "              actual_type = count_cocina\n",
        "            elif data_type == \"Deportes\":\n",
        "              count_deportes += 1\n",
        "              actual_type = count_deportes\n",
        "            elif data_type == \"Viaje\":\n",
        "              count_viaje += 1\n",
        "              actual_type = count_viaje\n",
        "\n",
        "            data_videos = data['videos']\n",
        "            print(data[\"channel\"])\n",
        "            print(len(data_videos))\n",
        "            for video in data_videos:\n",
        "              if actual_type <= 7:\n",
        "                if video['description'] == \"\":\n",
        "                  missing+=1\n",
        "                train_data.append(video['description'])\n",
        "                train_labels.append(data['type'])\n",
        "              else:\n",
        "                if video['description'] == \"\":\n",
        "                  missing+=1\n",
        "                val_data.append(video['description'])\n",
        "                val_labels.append(data['type'])\n",
        "\n",
        "# Verificamos el tamaño de los conjuntos de entrenamiento y validación\n",
        "print(f\"Tamaño de datos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Tamaño de datos de validación: {len(val_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDvurUmTg0DU",
        "outputId": "13f92f98-c98c-4efa-a4bc-e3bd294d2fc1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESPN Deportes\n",
            "100\n",
            "Hatch - NBA\n",
            "49\n",
            "Mundo Maldini\n",
            "100\n",
            "Leandro Carranza - Análisis NBA\n",
            "100\n",
            "Cracks\n",
            "100\n",
            "demas6Basket\n",
            "100\n",
            "ACB\n",
            "54\n",
            "La Media Inglesa\n",
            "100\n",
            "TyC Sports\n",
            "100\n",
            "Tamaño de datos de entrenamiento: 603\n",
            "Tamaño de datos de validación: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamos a los distintos clasificadores"
      ],
      "metadata": {
        "id": "0TVhBooZqWg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para LinearSVC"
      ],
      "metadata": {
        "id": "i4YZo8Q8rq4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Creamos el pipeline de TF con LinearSVC\n",
        "clf_tf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5)),])\n",
        "\n",
        "# Creamos el pipeline de TFIDF con LinearSVC y lo guardamos en clf_tfidf\n",
        "clf_tfidf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5)),])\n",
        "\n",
        "# Entrenamos el modelo de TF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tf.fit(train_data, train_labels)\n",
        "\n",
        "# Entrenamos el modelo de TFIDF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tfidf.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "LuADynXMnyUt",
        "outputId": "2889ea01-7899-44bf-d02b-759eb4faf9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', LinearSVC(random_state=0, tol=1e-05))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, LinearSVC(random_state=0, tol=1e-05))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, LinearSVC(random_state=0, tol=1e-05))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0, tol=1e-05)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para Random Forest"
      ],
      "metadata": {
        "id": "yNw1EjatrtrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Creamos el pipeline de TF con RandomForestClassifier\n",
        "clf_tf_rf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', RandomForestClassifier(random_state=0)),])\n",
        "\n",
        "# Creamos el pipeline de TFIDF con RandomForestClassifier y lo guardamos en clf_tfidf_rf\n",
        "clf_tfidf_rf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', RandomForestClassifier(random_state=0)),])\n",
        "\n",
        "# Entrenamos el modelo de TF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tf_rf.fit(train_data, train_labels)\n",
        "\n",
        "# Entrenamos el modelo de TFIDF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tfidf_rf.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "nK7hmNiipZU-",
        "outputId": "2fced020-6e60-43af-e7dd-69b31bc22a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', RandomForestClassifier(random_state=0))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, RandomForestClassifier(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, RandomForestClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para Gradient Boosting"
      ],
      "metadata": {
        "id": "Y_hyTkNlrwVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Creamos el pipeline de TF con Gradient Boosting\n",
        "clf_tf_gb = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', GradientBoostingClassifier(random_state=0)),])\n",
        "\n",
        "# Creamos el pipeline de TFIDF con Gradient Boosting\n",
        "clf_tfidf_gb = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', GradientBoostingClassifier(random_state=0)),])\n",
        "\n",
        "# Entrenamos el modelo de TF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tf_gb.fit(train_data, train_labels)\n",
        "\n",
        "# Entrenamos el modelo de TFIDF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tfidf_gb.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "ZHhq64hbqZ7e",
        "outputId": "a5c41e29-af43-4ebe-a72e-aa1e1883febc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', GradientBoostingClassifier(random_state=0))])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, GradientBoostingClassifier(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, GradientBoostingClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos resultados de validacion"
      ],
      "metadata": {
        "id": "-UwU9jYFqTym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Evaluamos el TF\n",
        "predicted_tf = clf_tf.predict(val_data)\n",
        "accuracy_tf = np.mean(predicted_tf == val_labels)\n",
        "\n",
        "print(\"Resultados TF ----- Accuracy:\", accuracy_tf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(val_labels, predicted_tf))\n",
        "\n",
        "# Evaluamos el TFIDF\n",
        "predicted_tfidf = clf_tfidf.predict(val_data)\n",
        "accuracy_tfidf = np.mean(predicted_tfidf == val_labels)\n",
        "\n",
        "print(\"Resultados TFIDF ----- Accuracy:\", accuracy_tfidf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(val_labels, predicted_tfidf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EqUwv4smDec",
        "outputId": "c3c8ca2e-19af-4029-cfad-9fdf1694c2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados TF ----- Accuracy: 0.5933333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Cocina       0.60      0.18      0.28       150\n",
            "    Deportes       0.60      0.83      0.70       150\n",
            "       Viaje       0.59      0.77      0.66       150\n",
            "\n",
            "    accuracy                           0.59       450\n",
            "   macro avg       0.59      0.59      0.55       450\n",
            "weighted avg       0.59      0.59      0.55       450\n",
            "\n",
            "Resultados TFIDF ----- Accuracy: 0.6622222222222223\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Cocina       0.87      0.27      0.41       150\n",
            "    Deportes       0.66      0.88      0.75       150\n",
            "       Viaje       0.62      0.84      0.71       150\n",
            "\n",
            "    accuracy                           0.66       450\n",
            "   macro avg       0.72      0.66      0.62       450\n",
            "weighted avg       0.72      0.66      0.62       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el TF\n",
        "predicted_tf = clf_tf_rf.predict(val_data)\n",
        "accuracy_tf = np.mean(predicted_tf == val_labels)\n",
        "\n",
        "print(\"Resultados TF ----- Accuracy:\", accuracy_tf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(val_labels, predicted_tf))\n",
        "\n",
        "# Evaluamos el TFIDF\n",
        "predicted_tfidf = clf_tfidf_rf.predict(val_data)\n",
        "accuracy_tfidf = np.mean(predicted_tfidf == val_labels)\n",
        "\n",
        "print(\"Resultados TFIDF ----- Accuracy:\", accuracy_tfidf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(val_labels, predicted_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pORZGbpdk1",
        "outputId": "a7e52017-080a-4d91-c6ac-bbfcfe29b936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados TF ----- Accuracy: 0.64\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Cocina       0.88      0.49      0.63       150\n",
            "    Deportes       0.52      0.83      0.64       150\n",
            "       Viaje       0.71      0.60      0.65       150\n",
            "\n",
            "    accuracy                           0.64       450\n",
            "   macro avg       0.70      0.64      0.64       450\n",
            "weighted avg       0.70      0.64      0.64       450\n",
            "\n",
            "Resultados TFIDF ----- Accuracy: 0.6444444444444445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Cocina       0.87      0.51      0.64       150\n",
            "    Deportes       0.51      0.83      0.64       150\n",
            "       Viaje       0.74      0.59      0.66       150\n",
            "\n",
            "    accuracy                           0.64       450\n",
            "   macro avg       0.71      0.64      0.65       450\n",
            "weighted avg       0.71      0.64      0.65       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el TF\n",
        "predicted_tf = clf_tf_gb.predict(val_data)\n",
        "accuracy_tf = np.mean(predicted_tf == val_labels)\n",
        "\n",
        "print(\"Resultados TF ----- Accuracy:\", accuracy_tf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(val_labels, predicted_tf))\n",
        "\n",
        "# Evaluamos el TFIDF\n",
        "predicted_tfidf = clf_tfidf_gb.predict(val_data)\n",
        "accuracy_tfidf = np.mean(predicted_tfidf == val_labels)\n",
        "\n",
        "print(\"Resultados TFIDF ----- Accuracy:\", accuracy_tfidf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(val_labels, predicted_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhPn2tyvrcHe",
        "outputId": "c1b0a8d0-3804-4ba4-a0a8-c0b2e58b3424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados TF ----- Accuracy: 0.6177777777777778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Cocina       0.86      0.46      0.60       150\n",
            "    Deportes       0.47      0.81      0.60       150\n",
            "       Viaje       0.77      0.59      0.67       150\n",
            "\n",
            "    accuracy                           0.62       450\n",
            "   macro avg       0.70      0.62      0.62       450\n",
            "weighted avg       0.70      0.62      0.62       450\n",
            "\n",
            "Resultados TFIDF ----- Accuracy: 0.6844444444444444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Cocina       0.94      0.53      0.68       150\n",
            "    Deportes       0.53      0.94      0.68       150\n",
            "       Viaje       0.89      0.59      0.71       150\n",
            "\n",
            "    accuracy                           0.68       450\n",
            "   macro avg       0.79      0.68      0.69       450\n",
            "weighted avg       0.79      0.68      0.69       450\n",
            "\n"
          ]
        }
      ]
    }
  ]
}