{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKpHNHF9pAnM"
      },
      "source": [
        "# Sesión 1 - Parte 2. Stanza\n",
        "\n",
        "Stanza es una API que proporciona sevicios de PLN organizados en tuberías o Pipelines.\n",
        "\n",
        "El objetivo de la práctica es crear un pipeline de Stanza en español e ir procesando un texto de ejemplo.\n",
        "\n",
        "Lo primero que haremos será instalar Stanza y descargar el modelo en español. Tened en cuenta que se pueden descargar modelos en distintos idiomas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mn79_2fpAIH"
      },
      "outputs": [],
      "source": [
        "!pip3 install stanza\n",
        "import stanza\n",
        "stanza.download('es')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC0vlPZCajed"
      },
      "source": [
        "## Apartado 1.1 - Resuelto\n",
        "\n",
        "Definimos un texto en español de varias líneas y probamos el Tokenizer en español.\n",
        "\n",
        "Para ello se definirá un Pipeline de Stanza únicamente con la fase 'tokenize'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwKTCxlLo93W"
      },
      "outputs": [],
      "source": [
        "#Probamos el tokenizer en español\n",
        "text = \"\"\"Hugo come manzanas en la cocina de Telefónica.\n",
        "\n",
        "Sofía juega al fútbol con Emma y Cristina con una pelota roja en Central Park.\n",
        "\n",
        "El padre de Marina tiene 56 años.\n",
        "\n",
        "La Tierra gira alrededor del Sol.\n",
        "\n",
        "Júpiter es el planeta más grande del Sistema Solar\"\"\"\n",
        "\n",
        "pipelineStanza = stanza.Pipeline(lang='es', processors='tokenize')\n",
        "stanzaDoc = pipelineStanza(text)\n",
        "\n",
        "print(\"Número de frases:\" + str(len(stanzaDoc.sentences)))\n",
        "for sentence in stanzaDoc.sentences:\n",
        "  print(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtenemos una matriz con todos los tokens por frase\n",
        "\n"
      ],
      "metadata": {
        "id": "RUcibdObcv-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Qka9GjhD6T"
      },
      "source": [
        "## Apartado 1.2\n",
        "\n",
        "Ahora vamos a probar el pipeline metiendo un analizador morfológico esto es 'tokenize, mwt, pos'\n",
        "\n",
        "Mostramos entonces cada palabra (*word*) de cada frase (*sentence*) junto con su categoría gramatical (*upos*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_mI1jDhhQE5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmGedD4NiprS"
      },
      "source": [
        "## Apartado 1.3\n",
        "\n",
        "A continuación incluimos en el Pipeline la lemmatización (*lemma*) y la imprimimos al lado de la palabra entre paréntesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKaaUan9ipIS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwbTm-wzWQ7T"
      },
      "source": [
        "## Apartado 1.4\n",
        "Ahora incluimos en el Pipeline que se haga un análisis de dependencias (*depparse*)\n",
        "\n",
        "Obtenemos entonces por cada frase la raiz principial (*root*) y su sujeto (*nsubj*).\n",
        "\n",
        "(Opcional) Mostrar también sus complementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-rCxrdMWQ7T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHlh-aD9mVi0"
      },
      "source": [
        "## Apartado 1.5\n",
        "\n",
        "Por último, incluimos una detección de entidades (*ner*) en el Pipeline y mostramos únicamente las entidades de cada frase que se encuentran en la colección *ents* de *sentence*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJaXD-rbieCi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}